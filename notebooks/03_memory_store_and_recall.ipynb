{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Memory Store & Recall: Context-Enhanced Responses\n",
    "\n",
    "This notebook demonstrates **how memory transforms agent responses** by comparing\n",
    "answers **with** and **without** memory context.\n",
    "\n",
    "## What You'll Learn\n",
    "1. **Baseline** - LLM response without any memory (generic, unhelpful)\n",
    "2. **Hybrid recall** - how ST + LT memories are retrieved with a token budget\n",
    "3. **Context injection** - how recalled memories enhance LLM responses\n",
    "4. **Token budget** - how the 60/40 ST/LT split works\n",
    "5. **Full agent loop** - multi-turn conversation where memory progressively improves answers\n",
    "\n",
    "## Prerequisites\n",
    "- Run Notebook 02 first (to populate ST and LT memories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/machinelearningzuu/Dropbox/Zuu Crew/Courses/üöß AI Engineer Essentials/Codes/Agentic Memory Design/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì Supabase SQL engine created\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úÖ Supabase connection test: SUCCESS\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úÖ pgvector extension: INSTALLED\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì Schema validation passed: vector(1536)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì Database tables created/verified\u001b[0m\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m‚úÖ Short-term memory : Supabase (st_turns)\u001b[0m\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m‚úÖ Long-term memory  : Supabase pgvector\u001b[0m\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m‚úÖ Recaller          : ready\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#  Setup ‚îÄ\n",
    "import sys, os, re\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure loguru\n",
    "from infrastructure.log import setup_logging\n",
    "from loguru import logger\n",
    "setup_logging(\"INFO\", for_notebook=True)\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from memory import (\n",
    "    ShortTermMemoryStore,\n",
    "    LongTermMemoryStore,\n",
    "    MemoryRecaller,\n",
    ")\n",
    "from services.crm_service import get_crm_client\n",
    "from infrastructure.db import create_tables, get_sql_engine\n",
    "from infrastructure.db.crm_models import Patient, Booking, Doctor, Location, Specialty\n",
    "from infrastructure.llm import get_chat_llm, get_default_embeddings\n",
    "\n",
    "create_tables()\n",
    "embedder = get_default_embeddings()\n",
    "llm = get_chat_llm()\n",
    "crm = get_crm_client()\n",
    "\n",
    "st_store = ShortTermMemoryStore()\n",
    "lt_store = LongTermMemoryStore(embedder)\n",
    "recaller = MemoryRecaller(st_store, lt_store)\n",
    "\n",
    "logger.success(\"‚úÖ Short-term memory : Supabase (st_turns)\")\n",
    "logger.success(\"‚úÖ Long-term memory  : Supabase pgvector\")\n",
    "logger.success(\"‚úÖ Recaller          : ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1 ¬∑ Baseline - Query WITHOUT Memory\n",
    "\n",
    "The LLM has **no context** about the user. Answers are generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Query: What medications does Anushka take and does she have any allergies?\n",
      "\n",
      "ü§ñ Baseline Answer (NO memory):\n",
      "------------------------------------------------------------\n",
      "I cannot provide you with information about Anushka's medications or allergies. That kind of information is private medical data and I do not have access to it.\n",
      "------------------------------------------------------------\n",
      "\u001b[31m\u001b[1m‚ùå\u001b[0m \u001b[31m\u001b[1m\n",
      "‚ùå The LLM has no idea about the user - generic / unhelpful response.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "query = \"What medications does Anushka take and does she have any allergies?\"\n",
    "\n",
    "print(f\"üìù Query: {query}\")\n",
    "print(\"\\nü§ñ Baseline Answer (NO memory):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "response = llm.invoke(query)\n",
    "baseline_answer = response.content if hasattr(response, \"content\") else str(response)\n",
    "print(baseline_answer)\n",
    "print(\"-\" * 60)\n",
    "logger.error(\"\\n‚ùå The LLM has no idea about the user - generic / unhelpful response.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 ¬∑ Hybrid Memory Recall (ST + LT)\n",
    "\n",
    "The `MemoryRecaller` combines:\n",
    "- **Short-term (60% budget)**: Recent conversation turns (conversational continuity)\n",
    "- **Long-term (40% budget)**: Distilled facts retrieved via cosine similarity (personalisation)\n",
    "\n",
    "Both are subject to a **token budget** (default: 500 tokens) to keep prompts efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m   Normalised ‚Üí 94781030736\u001b[0m\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1müì± Extracted phone ‚Üí user_id = 94781030736\u001b[0m\n",
      "üìã Patient Record  (Supabase ‚Üí patients table)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_d80b3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_d80b3_level0_col0\" class=\"col_heading level0 col0\" >Field</th>\n",
       "      <th id=\"T_d80b3_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_d80b3_row0_col0\" class=\"data row0 col0\" >Patient ID</td>\n",
       "      <td id=\"T_d80b3_row0_col1\" class=\"data row0 col1\" >12692f5d-1630-4ecd-bf7e-bcfd08260b73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d80b3_row1_col0\" class=\"data row1 col0\" >Full Name</td>\n",
       "      <td id=\"T_d80b3_row1_col1\" class=\"data row1 col1\" >Anushka Perera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d80b3_row2_col0\" class=\"data row2 col0\" >Phone</td>\n",
       "      <td id=\"T_d80b3_row2_col1\" class=\"data row2 col1\" >+94781030736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_d80b3_row3_col0\" class=\"data row3 col0\" >DOB</td>\n",
       "      <td id=\"T_d80b3_row3_col1\" class=\"data row3 col1\" >1985-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11da0f490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Recalling memories...\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "üì§ Retrieved:\n",
      "  Short-term turns : 4\n",
      "  Long-term facts  : 3\n",
      "\n",
      " Short-Term (recent conversation) \n",
      "  üë§ I'm allergic to penicillin, please always remember this.\n",
      "  ü§ñ Important! I've noted your penicillin allergy. This is critical information.\n",
      "  üë§ Also remind me that I have a meniscus tear follow-up with orthopedics.\n",
      "  ü§ñ Noted! I'll remember your orthopedics follow-up for the meniscus tear.\n",
      "\n",
      " Long-Term (distilled facts) \n",
      "  1. Anushka is allergic to penicillin.  [tags: allergy, penicillin, allergic_reaction]\n",
      "  2. Anushka is allergic to penicillin.  [tags: allergy, penicillin, allergic_reaction, important]\n",
      "  3. Anushka needs to inform her doctor about current medications  [tags: medication, communication, appointment]\n"
     ]
    }
   ],
   "source": [
    "#  Intelligent phone extraction ‚îÄ\n",
    "def extract_phone(text: str) -> str:\n",
    "    \"\"\"Extract and normalise a Sri Lankan phone number from free-form text.\"\"\"\n",
    "    match = re.search(r\"\\+?[\\d][\\d\\s\\-\\.\\(\\)]{7,18}[\\d]\", text)\n",
    "    if not match:\n",
    "        raise ValueError(\"‚ùå No phone number found in the message!\")\n",
    "    raw = re.sub(r\"\\D\", \"\", match.group())\n",
    "    if raw.startswith(\"0\") and len(raw) == 10:\n",
    "        raw = \"94\" + raw[1:]           # local ‚Üí international\n",
    "    elif len(raw) == 9 and not raw.startswith(\"94\"):\n",
    "        raw = \"94\" + raw               # bare subscriber number\n",
    "    logger.info(f\"   Normalised ‚Üí {raw}\")\n",
    "    return raw\n",
    "\n",
    "\n",
    "#  Identify user from a chat message (same as NB02) ‚îÄ\n",
    "# Using a different format to show the extractor handles it\n",
    "greeting = \"I'm back! It's Anushka. My mobile is +94-781-030-736, checking on my records.\"\n",
    "\n",
    "user_id = extract_phone(greeting)\n",
    "logger.success(f\"üì± Extracted phone ‚Üí user_id = {user_id}\")\n",
    "\n",
    "session_id = \"nb02-demo\"   # same session as NB02 so we can recall its turns\n",
    "\n",
    "#  Show patient record from CRM \n",
    "patient = crm.get_patient_by_user_id(user_id)\n",
    "if patient:\n",
    "    df = pd.DataFrame([{\n",
    "        \"Field\": k, \"Value\": v\n",
    "    } for k, v in {\n",
    "        \"Patient ID\": patient[\"patient_id\"],\n",
    "        \"Full Name\": patient[\"full_name\"],\n",
    "        \"Phone\": patient.get(\"phone\", \"-\"),\n",
    "        \"DOB\": patient.get(\"dob\", \"-\"),\n",
    "    }.items()])\n",
    "    print(\"üìã Patient Record  (Supabase ‚Üí patients table)\")\n",
    "    display(df.style.hide(axis=\"index\"))\n",
    "else:\n",
    "    logger.warning(\"‚ö†Ô∏è  Patient not found in CRM\")\n",
    "\n",
    "#  Recall memories for this user \n",
    "print(\"\\nüß† Recalling memories...\\n\")\n",
    "\n",
    "st_turns, lt_facts = recaller.recall(\n",
    "    user_id=user_id,\n",
    "    session_id=session_id,\n",
    "    query=query,\n",
    "    k_st=6,\n",
    "    k_lt=5,\n",
    "    max_tokens=500,\n",
    ")\n",
    "\n",
    "print(f\"üì§ Retrieved:\")\n",
    "print(f\"  Short-term turns : {len(st_turns)}\")\n",
    "print(f\"  Long-term facts  : {len(lt_facts)}\")\n",
    "\n",
    "# Show what was recalled\n",
    "if st_turns:\n",
    "    print(f\"\\n Short-Term (recent conversation) \")\n",
    "    for t in st_turns:\n",
    "        emoji = \"üë§\" if t.role == \"user\" else \"ü§ñ\"\n",
    "        print(f\"  {emoji} {t.content[:80]}\")\n",
    "\n",
    "if lt_facts:\n",
    "    print(f\"\\n Long-Term (distilled facts) \")\n",
    "    for i, f in enumerate(lt_facts, 1):\n",
    "        print(f\"  {i}. {f.text}  [tags: {', '.join(f.tags)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3 ¬∑ Token Budget Analysis\n",
    "\n",
    "The recaller allocates tokens: **60% short-term, 40% long-term** within a 500-token cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Token Budget Allocation:\n",
      "   Target  : ‚â§500 tokens\n",
      "   Actual  : 97 tokens\n",
      "\n",
      "   ST (60% target) : 66 tokens (68.0%)\n",
      "   LT (40% target) : 31 tokens (32.0%)\n",
      "\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m   ‚úÖ Within budget!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "st_tokens = sum(recaller.count_tokens(t.content) for t in st_turns)\n",
    "lt_tokens = sum(recaller.count_tokens(f.text) for f in lt_facts)\n",
    "total_tokens = st_tokens + lt_tokens\n",
    "\n",
    "print(\"üìä Token Budget Allocation:\")\n",
    "print(f\"   Target  : ‚â§500 tokens\")\n",
    "print(f\"   Actual  : {total_tokens} tokens\")\n",
    "print()\n",
    "if total_tokens > 0:\n",
    "    print(f\"   ST (60% target) : {st_tokens} tokens ({st_tokens/total_tokens*100:.1f}%)\")\n",
    "    print(f\"   LT (40% target) : {lt_tokens} tokens ({lt_tokens/total_tokens*100:.1f}%)\")\n",
    "print()\n",
    "logger.success(f\"   {'‚úÖ Within budget!' if total_tokens <= 500 else f'‚ö†Ô∏è Over budget by {total_tokens - 500} tokens'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4 ¬∑ Query WITH Memory Context\n",
    "\n",
    "Now we inject the recalled memories into the prompt and compare the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Memory context that gets injected into the prompt:\n",
      "\n",
      "=== RECENT CONVERSATION ===\n",
      "User: I'm allergic to penicillin, please always remember this.\n",
      "Assistant: Important! I've noted your penicillin allergy. This is critical information.\n",
      "User: Also remind me that I have a meniscus tear follow-up with orthopedics.\n",
      "Assistant: Noted! I'll remember your orthopedics follow-up for the meniscus tear.\n",
      "\n",
      "=== REMEMBERED FACTS ===\n",
      "1. Anushka is allergic to penicillin. [allergy, penicillin, allergic_reaction]\n",
      "2. Anushka is allergic to penicillin. [allergy, penicillin, allergic_reaction, important]\n",
      "3. Anushka needs to inform her doctor about current medications [medication, communication, appointment]\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Format recalled memories as a context string\n",
    "memory_context = recaller.format_context(st_turns, lt_facts)\n",
    "\n",
    "print(\"üìù Memory context that gets injected into the prompt:\\n\")\n",
    "print(memory_context)\n",
    "print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Query: What medications does Anushka take and does she have any allergies?\n",
      "\n",
      "ü§ñ Answer WITH Memory:\n",
      "------------------------------------------------------------\n",
      "Anushka is allergic to penicillin. I do not have information about what medications she takes.\n",
      "------------------------------------------------------------\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m\n",
      "‚úÖ With memory: the LLM knows the user's specific medications and schedule!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build prompt WITH memory and query the LLM\n",
    "prompt_with_memory = f\"\"\"{memory_context}\n",
    "\n",
    "USER QUERY: {query}\n",
    "\n",
    "Answer based on the information above:\"\"\"\n",
    "\n",
    "print(f\"üìù Query: {query}\")\n",
    "print(\"\\nü§ñ Answer WITH Memory:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "response = llm.invoke(prompt_with_memory)\n",
    "memory_answer = response.content if hasattr(response, \"content\") else str(response)\n",
    "print(memory_answer)\n",
    "print(\"-\" * 60)\n",
    "logger.success(\"\\n‚úÖ With memory: the LLM knows the user's specific medications and schedule!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5 ¬∑ Side-by-Side Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "üìä MEMORY RECALL EFFECTIVENESS\n",
      "========================================================================\n",
      "\u001b[31m\u001b[1m‚ùå\u001b[0m \u001b[31m\u001b[1m\n",
      "‚ùå WITHOUT Memory:\u001b[0m\n",
      "   I cannot provide you with information about Anushka's medications or allergies. That kind of information is private medical data and I do not have access to it.\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m\n",
      "‚úÖ WITH Memory (97 tokens injected):\u001b[0m\n",
      "   Anushka is allergic to penicillin. I do not have information about what medications she takes.\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m\n",
      "üéØ Key Benefit:\u001b[0m\n",
      "   Hybrid recall (60% ST / 40% LT) provides both:\n",
      "   ‚Ä¢ Conversational continuity (ST - what was just discussed)\n",
      "   ‚Ä¢ Long-term knowledge (LT - distilled facts and preferences)\n",
      "   ‚Ä¢ Token-efficient (97/500 tokens used)\n",
      "========================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 72)\n",
    "print(\"üìä MEMORY RECALL EFFECTIVENESS\")\n",
    "print(\"=\" * 72)\n",
    "\n",
    "logger.error(\"\\n‚ùå WITHOUT Memory:\")\n",
    "print(f\"   {baseline_answer[:200]}{'...' if len(baseline_answer) > 200 else ''}\")\n",
    "\n",
    "logger.success(f\"\\n‚úÖ WITH Memory ({total_tokens} tokens injected):\")\n",
    "print(f\"   {memory_answer[:200]}{'...' if len(memory_answer) > 200 else ''}\")\n",
    "\n",
    "logger.info(f\"\\nüéØ Key Benefit:\")\n",
    "print(f\"   Hybrid recall (60% ST / 40% LT) provides both:\")\n",
    "print(f\"   ‚Ä¢ Conversational continuity (ST - what was just discussed)\")\n",
    "print(f\"   ‚Ä¢ Long-term knowledge (LT - distilled facts and preferences)\")\n",
    "print(f\"   ‚Ä¢ Token-efficient ({total_tokens}/500 tokens used)\")\n",
    "print(\"=\" * 72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6 ¬∑ Full Agent with Memory - Progressive Context Building\n",
    "\n",
    "Watch how the **agent accumulates context** across multiple turns.\n",
    "Each turn adds to short-term memory; distillation extracts long-term facts.\n",
    "By the end, the agent knows the user deeply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mLangFuse client initialised (host=https://us.cloud.langfuse.com)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mLLM models loaded:\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m   Chat (synthesis) : google/gemini-2.5-flash\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m   Router           : openai/gpt-4o-mini\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m   Extractor        : llama-3.1-8b-instant\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì CRM tool loaded\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mConnected to Qdrant Cloud at https://025872ed-03a9-42c8-84ff-5caad58a460b.us-east-1-1.aws.cloud.qdrant.io\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì Qdrant KB ready - collection 'nawaloka' has 124 points, skipping ingestion\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì CAG cache ready (Qdrant collection='cag_cache', dim=1536, threshold=0.90)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRAGTool initialised: CAG cache (CAGCache(collection='cag_cache', threshold=0.9, ttl=86400s, entries=68, backend='qdrant')) -> CRAG (k=4, expanded_k=8, threshold=0.60)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì RAG tool loaded (CAG-enabled)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the working hours and shift timings at Na' ‚Üí matched 'What are the working hours and shift timings at Na'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the leave policy for permanent employees?' ‚Üí matched 'What is the leave policy for permanent employees?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How many sick days do employees get?' ‚Üí matched 'How many sick days do employees get?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the maternity leave entitlement?' ‚Üí matched 'What is the maternity leave entitlement?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the dress code for clinical staff?' ‚Üí matched 'What is the dress code for clinical staff?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the employee medical benefits?' ‚Üí matched 'What are the employee medical benefits?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the disciplinary process at Nawaloka?' ‚Üí matched 'What is the disciplinary process at Nawaloka?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the patient admission process?' ‚Üí matched 'What is the patient admission process?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does the triage system work in the emergency d' ‚Üí matched 'How does the triage system work in the emergency d'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the ISBAR handover protocol?' ‚Üí matched 'What is the ISBAR handover protocol?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the discharge process for inpatients?' ‚Üí matched 'What is the discharge process for inpatients?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the five rights of medication administrat' ‚Üí matched 'What are the five rights of medication administrat'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the surgical safety checklist?' ‚Üí matched 'What is the surgical safety checklist?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the blood transfusion protocol?' ‚Üí matched 'What is the blood transfusion protocol?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the Code Blue procedure for cardiac arrest' ‚Üí matched 'What is the Code Blue procedure for cardiac arrest'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What should staff do in case of a fire emergency?' ‚Üí matched 'What should staff do in case of a fire emergency?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the Code Orange mass casualty protocol?' ‚Üí matched 'What is the Code Orange mass casualty protocol?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What happens during a power failure at the hospita' ‚Üí matched 'What happens during a power failure at the hospita'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the fire extinguisher types and their use' ‚Üí matched 'What are the fire extinguisher types and their use'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the hand hygiene policy?' ‚Üí matched 'What is the hand hygiene policy?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What PPE is required for airborne precautions?' ‚Üí matched 'What PPE is required for airborne precautions?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How many negative pressure isolation rooms does Na' ‚Üí matched 'How many negative pressure isolation rooms does Na'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the cleaning protocol for patient rooms?' ‚Üí matched 'What is the cleaning protocol for patient rooms?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the needlestick injury protocol?' ‚Üí matched 'What is the needlestick injury protocol?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does the antibiotic stewardship programme work' ‚Üí matched 'How does the antibiotic stewardship programme work'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How is patient identification verified?' ‚Üí matched 'How is patient identification verified?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the high-alert medications at Nawaloka?' ‚Üí matched 'What are the high-alert medications at Nawaloka?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the fall prevention programme?' ‚Üí matched 'What is the fall prevention programme?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How are medication errors reported?' ‚Üí matched 'How are medication errors reported?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the Braden Scale for pressure injury risk?' ‚Üí matched 'What is the Braden Scale for pressure injury risk?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does incident reporting work?' ‚Üí matched 'How does incident reporting work?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What cardiology services does Nawaloka offer?' ‚Üí matched 'What cardiology services does Nawaloka offer?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the STEMI door-to-balloon time target?' ‚Üí matched 'What is the STEMI door-to-balloon time target?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does the cardiac rehabilitation programme work' ‚Üí matched 'How does the cardiac rehabilitation programme work'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What tests are available in the non-invasive cardi' ‚Üí matched 'What tests are available in the non-invasive cardi'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the heart failure management pathway?' ‚Üí matched 'What is the heart failure management pathway?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What imaging equipment does Nawaloka have?' ‚Üí matched 'What imaging equipment does Nawaloka have?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What preparation is needed for an MRI scan?' ‚Üí matched 'What preparation is needed for an MRI scan?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the contrast reaction management protocol?' ‚Üí matched 'What is the contrast reaction management protocol?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the MRI safety contraindications?' ‚Üí matched 'What are the MRI safety contraindications?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How long does it take to get a radiology report?' ‚Üí matched 'How long does it take to get a radiology report?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the lab turnaround times?' ‚Üí matched 'What are the lab turnaround times?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the blood specimen tube colours and their' ‚Üí matched 'What are the blood specimen tube colours and their'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the critical lab values that require imme' ‚Üí matched 'What are the critical lab values that require imme'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does the blood bank manage emergency blood req' ‚Üí matched 'How does the blood bank manage emergency blood req'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What quality control measures does the laboratory ' ‚Üí matched 'What quality control measures does the laboratory '\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What are the pharmacy operating hours?' ‚Üí matched 'What are the pharmacy operating hours?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How are controlled substances managed?' ‚Üí matched 'How are controlled substances managed?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the therapeutic drug monitoring process?' ‚Üí matched 'What is the therapeutic drug monitoring process?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How are cytotoxic drugs handled?' ‚Üí matched 'How are cytotoxic drugs handled?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What drugs require TDM at Nawaloka?' ‚Üí matched 'What drugs require TDM at Nawaloka?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What payment methods does Nawaloka accept?' ‚Üí matched 'What payment methods does Nawaloka accept?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What insurance companies have direct billing agree' ‚Üí matched 'What insurance companies have direct billing agree'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the room charge for a private room?' ‚Üí matched 'What is the room charge for a private room?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How much does a coronary angiogram cost?' ‚Üí matched 'How much does a coronary angiogram cost?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the financial hardship policy?' ‚Üí matched 'What is the financial hardship policy?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the data privacy policy?' ‚Üí matched 'What is the data privacy policy?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How is patient data classified?' ‚Üí matched 'How is patient data classified?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the break-the-glass procedure for EMR acce' ‚Üí matched 'What is the break-the-glass procedure for EMR acce'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How long are patient records retained?' ‚Üí matched 'How long are patient records retained?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What happens in case of a data breach?' ‚Üí matched 'What happens in case of a data breach?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the new employee orientation programme?' ‚Üí matched 'What is the new employee orientation programme?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What mandatory training is required annually?' ‚Üí matched 'What mandatory training is required annually?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What CME requirements do doctors need to meet?' ‚Üí matched 'What CME requirements do doctors need to meet?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What simulation training facilities are available?' ‚Üí matched 'What simulation training facilities are available?'\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What nursing specialisation courses does Nawaloka ' ‚Üí matched 'What nursing specialisation courses does Nawaloka '\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì CAG cache already warm (66 FAQs)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m‚úì Web search tool loaded\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1m   Normalised ‚Üí 94781030736\u001b[0m\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1müì± Extracted phone ‚Üí RECALL_USER = 94781030736\u001b[0m\n",
      "üìã Patient Record  (Supabase ‚Üí patients table)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_b2ea0\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_b2ea0_level0_col0\" class=\"col_heading level0 col0\" >Field</th>\n",
       "      <th id=\"T_b2ea0_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_b2ea0_row0_col0\" class=\"data row0 col0\" >Full Name</td>\n",
       "      <td id=\"T_b2ea0_row0_col1\" class=\"data row0 col1\" >Anushka Perera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b2ea0_row1_col0\" class=\"data row1 col0\" >Phone</td>\n",
       "      <td id=\"T_b2ea0_row1_col1\" class=\"data row1 col1\" >+94781030736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_b2ea0_row2_col0\" class=\"data row2 col0\" >DOB</td>\n",
       "      <td id=\"T_b2ea0_row2_col1\" class=\"data row2 col1\" >1985-03-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x11defb490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ Progressive Memory Building\n",
      "========================================================================\n",
      "\n",
      "\n",
      "üë§ Turn 1: Hi, I'm Anushka. My mobile is 078 103 0736. I have a cardiac stress test coming up.\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: crm (action=lookup_patient, conf=0.90) - The user provided their mobile number and mentioned an upcoming cardiac stress test, indicating a need for patient lookup or related actions.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDispatching CRM action: lookup_patient params={'phone': '078 103 0736'}\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 4 facts to LT memory (0 new, 4 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 4 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: crm / lookup_patient\n",
      "üìù Memory context: 10 lines\n",
      "‚è±Ô∏è  25729ms\n",
      "ü§ñ Hello Anushka!\n",
      "\n",
      "It's great to hear from you. I see you have a cardiac stress test coming up. I've noted your mobile number, 078 103 0736, for future reference.\n",
      "\n",
      "Is there anything specific you'd like to know or do regarding your upcoming test? I'm here to help!\n",
      "\n",
      "\n",
      "üë§ Turn 2: I take atenolol 50mg every morning for blood pressure. Please remember this.\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: direct (action=None, conf=0.90) - The user is providing information about their medication routine, which can be noted without needing any specific action or tool.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 3 facts to LT memory (0 new, 3 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 3 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: direct\n",
      "üìù Memory context: 14 lines\n",
      "‚è±Ô∏è  10960ms\n",
      "ü§ñ Thank you, Anushka. I've noted that you take Atenolol 50mg every morning for blood pressure. I'll remember this for future reference. Is there anything else I can help you with today?\n",
      "\n",
      "\n",
      "üë§ Turn 3: I'm allergic to penicillin. Very important - always remember!\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: direct (action=None, conf=1.00) - The user is reiterating an important allergy that has already been noted, which does not require any action or tool.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 5 facts to LT memory (0 new, 5 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 5 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: direct\n",
      "üìù Memory context: 14 lines\n",
      "‚è±Ô∏è  11952ms\n",
      "ü§ñ Thank you for letting me know, Anushka. I've made a note that you are allergic to penicillin, and I understand it's very important. I will always remember this. Is there anything else I can assist you with today?\n",
      "\n",
      "\n",
      "üë§ Turn 4: Can you find me a cardiologist?\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: crm (action=search_doctors, conf=0.90) - The user is requesting assistance in finding a cardiologist, which falls under the patient lookup or doctor search category.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDispatching CRM action: search_doctors params={'specialty': 'cardiology', 'name': None, 'location': None}\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 6 facts to LT memory (1 new, 5 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 6 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: crm / search_doctors\n",
      "üìù Memory context: 10 lines\n",
      "‚è±Ô∏è  14118ms\n",
      "ü§ñ Certainly, Anushka. I can help you find a cardiologist.\n",
      "\n",
      "We have several excellent cardiologists available at Nawaloka Hospitals:\n",
      "\n",
      "*   **Dr. Priya Fernando**\n",
      "*   **Dr. Shalini Perera**\n",
      "*   **Dr. Nirmala Rajasingham**\n",
      "*   **Dr. Sita Thirunavukarasu**\n",
      "*   **Dr. Tharindu Sivasubramaniam**\n",
      "\n",
      "Would you li...\n",
      "\n",
      "\n",
      "üë§ Turn 5: What is the medication administration policy at the hospital?\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 5 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: rag (action=None, conf=0.90) - The user is inquiring about a specific hospital policy, which falls under the category of internal knowledge base.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDispatching RAG search: medication administration policy\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mCAG cache MISS -> cached for: medication administration policy\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 6 facts to LT memory (0 new, 6 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 6 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: rag\n",
      "üìù Memory context: 20 lines\n",
      "‚è±Ô∏è  16095ms\n",
      "ü§ñ I apologize, Anushka, but I don't have specific information about Nawaloka Hospital's medication administration policy in my current knowledge base.\n",
      "\n",
      "For details on this, I recommend calling Nawaloka Hospital directly at **+94 11 544 4444**. They will be able to provide you with the most accurate an...\n",
      "\n",
      "\n",
      "üë§ Turn 6: What do you remember about my health conditions and medications?\n",
      "\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRetrieved 3 facts from LT memory for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRecalled 4 ST turns, 3 LT facts for user 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mRoute: direct (action=None, conf=0.90) - The user is asking for information that can be answered from memory alone regarding their health conditions and medications.\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mTriggering memory distillation for 94781030736\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mUpserted 4 facts to LT memory (0 new, 4 merged)\u001b[0m\n",
      "\u001b[1m‚ÑπÔ∏è\u001b[0m \u001b[1mDistilled 4 facts for user 94781030736\u001b[0m\n",
      "üõ§Ô∏è  Route: direct\n",
      "üìù Memory context: 22 lines\n",
      "‚è±Ô∏è  11728ms\n",
      "ü§ñ Anushka, I don't have access to your personal health conditions or specific medications. My purpose is to assist you with information about Nawaloka Hospitals and help with appointments.\n",
      "\n",
      "However, I do remember that it's important for you to inform your doctor or nurse about any current medications ...\n",
      "\n",
      "========================================================================\n",
      "\u001b[32m\u001b[1m‚úÖ\u001b[0m \u001b[32m\u001b[1m‚úÖ Progressive memory building complete!\u001b[0m\n",
      "   Notice how memory_context grows with each turn.\n"
     ]
    }
   ],
   "source": [
    "from agents import build_agent\n",
    "\n",
    "agent = build_agent(enable_crm=True, enable_rag=True, enable_web=True)\n",
    "\n",
    "# The first message includes the user's phone - extract it like a real system\n",
    "# Using local format (078‚Ä¶) to show the normaliser in action\n",
    "first_msg = \"Hi, I'm Anushka. My mobile is 078 103 0736. I have a cardiac stress test coming up.\"\n",
    "\n",
    "RECALL_USER = extract_phone(first_msg)\n",
    "RECALL_SESSION = \"nb03-recall\"\n",
    "\n",
    "logger.success(f\"üì± Extracted phone ‚Üí RECALL_USER = {RECALL_USER}\")\n",
    "\n",
    "# Show patient info from CRM for context\n",
    "patient = crm.get_patient_by_user_id(RECALL_USER)\n",
    "if patient:\n",
    "    df = pd.DataFrame([{\n",
    "        \"Field\": k, \"Value\": v\n",
    "    } for k, v in {\n",
    "        \"Full Name\": patient[\"full_name\"],\n",
    "        \"Phone\": patient.get(\"phone\", \"-\"),\n",
    "        \"DOB\": patient.get(\"dob\", \"-\"),\n",
    "    }.items()])\n",
    "    print(\"üìã Patient Record  (Supabase ‚Üí patients table)\")\n",
    "    display(df.style.hide(axis=\"index\"))\n",
    "\n",
    "# A conversation that progressively builds memory\n",
    "# Tailored to Anushka Perera's CRM data:\n",
    "#   - Cardiology bookings (stress test, cardiac risk)\n",
    "#   - Orthopedics booking (meniscus tear)\n",
    "#   - Dermatology booking (actinic keratosis monitoring)\n",
    "messages = [\n",
    "    first_msg,                                                            # ‚Üí direct (identity + condition)\n",
    "    \"I take atenolol 50mg every morning for blood pressure. Please remember this.\",\n",
    "    \"I'm allergic to penicillin. Very important - always remember!\",\n",
    "    \"Can you find me a cardiologist?\",                                    # ‚Üí CRM tool\n",
    "    \"What is the medication administration policy at the hospital?\",       # ‚Üí RAG tool\n",
    "    \"What do you remember about my health conditions and medications?\",    # ‚Üí direct (from memory)\n",
    "]\n",
    "\n",
    "print(\"\\nüîÑ Progressive Memory Building\")\n",
    "print(\"=\" * 72)\n",
    "\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    print(f\"\\n{'‚îÄ' * 72}\")\n",
    "    print(f\"üë§ Turn {i}: {msg}\")\n",
    "    print(f\"{'‚îÄ' * 72}\")\n",
    "    \n",
    "    resp = agent.chat(\n",
    "        user_message=msg,\n",
    "        user_id=RECALL_USER,\n",
    "        session_id=RECALL_SESSION,\n",
    "    )\n",
    "    \n",
    "    # Show route and memory context size\n",
    "    ctx_lines = len(resp.memory_context.strip().split(\"\\n\")) if resp.memory_context.strip() else 0\n",
    "    print(f\"üõ§Ô∏è  Route: {resp.route}\" + (f\" / {resp.action}\" if resp.action else \"\"))\n",
    "    print(f\"üìù Memory context: {ctx_lines} lines\")\n",
    "    print(f\"‚è±Ô∏è  {resp.latency_ms}ms\")\n",
    "    print(f\"ü§ñ {resp.answer[:300]}{'...' if len(resp.answer) > 300 else ''}\")\n",
    "\n",
    "print(f\"\\n{'=' * 72}\")\n",
    "logger.success(\"‚úÖ Progressive memory building complete!\")\n",
    "print(\"   Notice how memory_context grows with each turn.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7 ¬∑ Memory Lifecycle Summary\n",
    "\n",
    "```\n",
    "Conversation Turn\n",
    "       ‚îÇ\n",
    "       ‚ñº\n",
    "‚îå‚îê\n",
    "‚îÇ  SHORT-TERM MEMORY   ‚îÇ  ‚Üê Stored immediately (ring buffer)\n",
    "‚îÇ  (last N turns)      ‚îÇ     Retrieved by recency\n",
    "‚îî‚î¨‚îÄ‚îò\n",
    "           ‚îÇ  distillation triggered?\n",
    "           ‚ñº\n",
    "‚îå‚îê\n",
    "‚îÇ  DISTILLER (LLM)     ‚îÇ  ‚Üê Extracts facts from conversation\n",
    "‚îÇ  \"remember\", ‚â•5 turns‚îÇ\n",
    "‚îî‚î¨‚îÄ‚îò\n",
    "           ‚îÇ\n",
    "           ‚ñº\n",
    "‚îå‚îê\n",
    "‚îÇ  LONG-TERM MEMORY    ‚îÇ  ‚Üê Stored with pgvector embedding\n",
    "‚îÇ  (semantic facts)    ‚îÇ     Retrieved by cosine similarity\n",
    "‚îî‚îò\n",
    "\n",
    "EPISODIC: Full sessions stored at end-of-conversation\n",
    "PROCEDURAL: Pre-loaded workflows retrieved by intent similarity\n",
    "```\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Memory makes agents personal** - the same LLM gives generic vs. specific answers\n",
    "2. **Token budget prevents bloat** - 60/40 ST/LT split within 500 tokens\n",
    "3. **Hybrid recall** - combines recency (ST) with relevance (LT cosine similarity)\n",
    "4. **Progressive context** - memory grows across turns within a session\n",
    "5. **Cross-session persistence** - LT facts survive across sessions (stored in pgvector)\n",
    "6. **Distillation is triggered** - not every turn distills, only when policy says so"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
