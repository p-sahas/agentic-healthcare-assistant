{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Agentic Routing Engine: End-to-End Pipeline\n",
    "\n",
    "This notebook demonstrates the **full agent system** from user query to final response.\n",
    "\n",
    "## Architecture\n",
    "\n",
    "```\n",
    "User Message\n",
    "     │\n",
    "     ▼\n",
    "┌┐\n",
    "│  1. MEMORY RECALL (ST turns + LT facts)          │\n",
    "│     → Recent conversation + distilled knowledge   │\n",
    "└┬─┘\n",
    "                       │\n",
    "                       ▼\n",
    "┌┐\n",
    "│  2. ROUTER (LLM intent classification)           │\n",
    "│     → crm | rag | web_search | direct            │\n",
    "└┬─┘\n",
    "                       │\n",
    "          ┌┼┐\n",
    "          ▼            ▼            ▼\n",
    "     ┌─┐ ┌─┐ ┌─┐\n",
    "     │   CRM   │ │   RAG   │ │ Web Search│\n",
    "     │  Tool   │ │  Tool   │ │   Tool    │\n",
    "     └┬┘ └┬┘ └─┬─┘\n",
    "          │           │            │\n",
    "          └─┼┘\n",
    "                      ▼\n",
    "┌┐\n",
    "│  4. SYNTHESISER (LLM merges memory + tool output)│\n",
    "│     → Natural, personalised response              │\n",
    "└┬─┘\n",
    "                       │\n",
    "                       ▼\n",
    "┌┐\n",
    "│  5. MEMORY STORE + DISTILL                       │\n",
    "│     → Save turn to ST · Extract LT facts          │\n",
    "└┘\n",
    "```\n",
    "\n",
    "## What You'll Learn\n",
    "1. How the **router** classifies user intent with JSON-structured LLM output\n",
    "2. How **3 tools** (CRM, RAG, Web Search) are dispatched based on the route\n",
    "3. How **memory** (short-term + long-term) is recalled and injected as context\n",
    "4. How the **synthesiser** merges tool output with memory to produce a final answer\n",
    "5. How **LangFuse** traces every step for full observability\n",
    "\n",
    "## Prerequisites\n",
    "- `.env` configured with API keys (OpenRouter, Supabase, Qdrant, Tavily, LangFuse)\n",
    "- CRM seeded: `make seed-crm-xl`\n",
    "- KB ingested: `make ingest-qdrant`\n",
    "- Procedures seeded: `python scripts/seed_procedures.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Setup ─\n",
    "import sys, os\n",
    "sys.path.insert(0, \"../src\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Configure loguru (clean notebook-friendly output)\n",
    "from infrastructure.log import setup_logging\n",
    "from loguru import logger\n",
    "\n",
    "setup_logging(\"INFO\", for_notebook=True)\n",
    "\n",
    "logger.success(\"Environment loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 · Build the Agent\n",
    "\n",
    "`build_agent()` is a factory function that wires together:\n",
    "- **LLM** (chat model via OpenRouter)\n",
    "- **Embedder** (OpenAI embeddings)\n",
    "- **Memory stores** (Short-term + Long-term + Episodic + Procedural)\n",
    "- **Tools** (CRM, RAG, Web Search)\n",
    "- **Router** (LLM-based intent classifier)\n",
    "- **Synthesiser** (LLM response generator)\n",
    "- **LangFuse** (observability - traces, spans, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mℹ️\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What is the Braden Scale for pressure injury risk?' → matched 'What is the Braden Scale for pressure injury risk?'\u001b[0m\n",
      "\u001b[1mℹ️\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'How does incident reporting work?' → matched 'How does incident reporting work?'\u001b[0m\n",
      "\u001b[1mℹ️\u001b[0m \u001b[1mCAG cache HIT (sim=1.000): 'What cardiology services does Nawaloka offer?' → matched 'What cardiology services does Nawaloka offer?'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from agents import build_agent, AgentResponse\n",
    "\n",
    "agent = build_agent(enable_crm=True, enable_rag=True, enable_web=True)\n",
    "\n",
    "logger.success(\"Agent built successfully\")\n",
    "logger.info(f\"   LLM model   : {agent._model_name()}\")\n",
    "logger.info(f\"   CRM tool    : {'✓' if agent.crm_tool else '✗'}\")\n",
    "logger.info(f\"   RAG tool    : {'✓' if agent.rag_tool else '✗'}\")\n",
    "logger.info(f\"   Web search  : {'✓' if agent.web_tool else '✗'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 · Helper — Pretty-Print Agent Response\n",
    "\n",
    "We'll use this throughout to visualise every field in `AgentResponse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from infrastructure.db import get_sql_engine\n",
    "from infrastructure.db.crm_models import Patient, Booking, Doctor, Location, Specialty\n",
    "\n",
    "\n",
    "#  Intelligent Phone Extraction ─\n",
    "# Users type phone numbers in many formats.  This helper handles\n",
    "# them all and normalises to the CRM's `external_user_id` format\n",
    "# (e.g. \"94781030736\" - digits only, with country prefix).\n",
    "\n",
    "def extract_phone(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract and normalise a Sri Lankan phone number from free-form text.\n",
    "\n",
    "    Handles all common formats:\n",
    "      \"+94 78 10 30 736\"  →  94781030736\n",
    "      \"0781030736\"        →  94781030736\n",
    "      \"94781030736\"       →  94781030736\n",
    "      \"+94-781-030-736\"   →  94781030736\n",
    "      \"078 103 0736\"      →  94781030736\n",
    "      \"(078) 103-0736\"    →  94781030736\n",
    "\n",
    "    Returns:\n",
    "        Normalised number (digits only, '94' country prefix) matching\n",
    "        the CRM `patients.external_user_id` column.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if no phone-like sequence is found in *text*.\n",
    "    \"\"\"\n",
    "    # Match a phone-like run: optional '+' then digits mixed with spaces / dashes / dots / parens\n",
    "    match = re.search(r\"\\+?[\\d][\\d\\s\\-\\.\\(\\)]{7,18}[\\d]\", text)\n",
    "    if not match:\n",
    "        raise ValueError(\" No phone number found in the message!\")\n",
    "\n",
    "    # Strip everything except digits\n",
    "    raw = re.sub(r\"\\D\", \"\", match.group())\n",
    "\n",
    "    # Normalise to Sri Lankan international format (94XXXXXXXXX)\n",
    "    if raw.startswith(\"0\") and len(raw) == 10:\n",
    "        # Local format: 0781030736 → 94781030736\n",
    "        raw = \"94\" + raw[1:]\n",
    "    elif raw.startswith(\"94\") and len(raw) == 11:\n",
    "        # Already international - keep as-is\n",
    "        pass\n",
    "    elif len(raw) == 9 and not raw.startswith(\"94\"):\n",
    "        # Bare subscriber number without prefix (781030736)\n",
    "        raw = \"94\" + raw\n",
    "\n",
    "    logger.info(f\"   Normalised → {raw}\")\n",
    "    return raw\n",
    "\n",
    "\n",
    "def show_response(resp: AgentResponse, label: str = \"\") -> None:\n",
    "    \"\"\"Pretty-print an AgentResponse.\"\"\"\n",
    "    print(\"=\" * 72)\n",
    "    if label:\n",
    "        print(f\"  {label}\")\n",
    "    print(\"=\" * 72)\n",
    "    print(f\"\\n  Route     : {resp.route}\")\n",
    "    if resp.action:\n",
    "        print(f\" Action    : {resp.action}\")\n",
    "    print(f\"⏱  Latency   : {resp.latency_ms} ms\")\n",
    "\n",
    "    # Memory context used\n",
    "    if resp.memory_context and resp.memory_context.strip():\n",
    "        print(f\"\\n Memory Context:\")\n",
    "        for line in resp.memory_context.strip().split(\"\\n\")[:8]:\n",
    "            print(f\"   {line}\")\n",
    "        ctx_lines = resp.memory_context.strip().split(\"\\n\")\n",
    "        if len(ctx_lines) > 8:\n",
    "            print(f\"   ... ({len(ctx_lines) - 8} more lines)\")\n",
    "    else:\n",
    "        print(f\"\\n Memory Context: (none)\")\n",
    "\n",
    "    # Tool output\n",
    "    if resp.tool_output and resp.tool_output.strip():\n",
    "        print(f\"\\n Tool Output:\")\n",
    "        for line in resp.tool_output.strip().split(\"\\n\")[:10]:\n",
    "            print(f\"   {line}\")\n",
    "        out_lines = resp.tool_output.strip().split(\"\\n\")\n",
    "        if len(out_lines) > 10:\n",
    "            print(f\"   ... ({len(out_lines) - 10} more lines)\")\n",
    "\n",
    "    # Final answer\n",
    "    print(f\"\\n Answer:\")\n",
    "    print(f\"   {resp.answer}\")\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "\n",
    "#  CRM Table Helpers \n",
    "# These query the Supabase CRM tables directly and display\n",
    "# the results as pandas DataFrames so students can see what's\n",
    "# actually stored in the database.\n",
    "\n",
    "def _crm_session():\n",
    "    \"\"\"Create a fresh SQLAlchemy session for CRM queries.\"\"\"\n",
    "    return sessionmaker(bind=get_sql_engine())()\n",
    "\n",
    "\n",
    "def show_patient_table(user_id: str) -> dict | None:\n",
    "    \"\"\"Look up a patient by external_user_id and display as a table.\"\"\"\n",
    "    session = _crm_session()\n",
    "    try:\n",
    "        patient = (\n",
    "            session.query(Patient)\n",
    "            .filter(Patient.external_user_id == user_id)\n",
    "            .first()\n",
    "        )\n",
    "        if not patient:\n",
    "            logger.warning(f\"No patient found for user_id={user_id}\")\n",
    "            return None\n",
    "\n",
    "        info = {\n",
    "            \"Patient ID\": patient.patient_id,\n",
    "            \"Full Name\": patient.full_name,\n",
    "            \"Phone\": patient.phone,\n",
    "            \"Email\": patient.email or \"-\",\n",
    "            \"DOB\": patient.dob or \"-\",\n",
    "            \"Gender\": {\"M\": \"Male\", \"F\": \"Female\", \"X\": \"Other\"}.get(\n",
    "                patient.gender or \"\", patient.gender or \"-\"\n",
    "            ),\n",
    "            \"Notes\": (patient.notes or \"-\")[:80],\n",
    "        }\n",
    "        df = pd.DataFrame([{\"Field\": k, \"Value\": v} for k, v in info.items()])\n",
    "        print(\" Patient Record  (Supabase → patients table)\")\n",
    "        display(df.style.hide(axis=\"index\"))\n",
    "        return patient.to_dict()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "def show_bookings_table(user_id: str) -> None:\n",
    "    \"\"\"Show upcoming bookings for a user as a table.\"\"\"\n",
    "    session = _crm_session()\n",
    "    try:\n",
    "        patient = (\n",
    "            session.query(Patient)\n",
    "            .filter(Patient.external_user_id == user_id)\n",
    "            .first()\n",
    "        )\n",
    "        if not patient:\n",
    "            return\n",
    "\n",
    "        rows_raw = (\n",
    "            session.query(Booking, Doctor, Location)\n",
    "            .join(Doctor, Booking.doctor_id == Doctor.doctor_id)\n",
    "            .join(Location, Booking.location_id == Location.location_id)\n",
    "            .filter(Booking.patient_id == patient.patient_id)\n",
    "            .order_by(Booking.start_at.desc())\n",
    "            .limit(10)\n",
    "            .all()\n",
    "        )\n",
    "        if not rows_raw:\n",
    "            print(\" No bookings found for this patient.\")\n",
    "            return\n",
    "\n",
    "        rows = []\n",
    "        for bk, doc, loc in rows_raw:\n",
    "            spec = (\n",
    "                session.get(Specialty, doc.specialty_id)\n",
    "                if doc.specialty_id else None\n",
    "            )\n",
    "            rows.append({\n",
    "                \"Date\": datetime.fromtimestamp(bk.start_at).strftime(\"%Y-%m-%d %H:%M\"),\n",
    "                \"Doctor\": f\"Dr. {doc.full_name}\",\n",
    "                \"Specialty\": spec.name if spec else \"-\",\n",
    "                \"Location\": loc.name,\n",
    "                \"Status\": bk.status,\n",
    "                \"Reason\": bk.reason or \"-\",\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        print(f\"\\n Bookings  ({len(rows)} records from Supabase → bookings table)\")\n",
    "        display(df)\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "logger.success(\"Helpers ready: show_response, show_patient_table, show_bookings_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 · User Identification — Extract Identity from Chat\n",
    "\n",
    "In a real system, the user's identity comes through the conversation itself\n",
    "(e.g. *\"Hi, my mobile is 077…\"*), not a hardcoded variable.\n",
    "\n",
    "Here we simulate that: the user sends a greeting that includes their **phone number**.\n",
    "The `extract_phone()` helper intelligently handles **any format**:\n",
    "\n",
    "| User types | Normalised to |\n",
    "|------------|---------------|\n",
    "| `+94 78 10 30 736` | `94781030736` |\n",
    "| `0781030736` | `94781030736` |\n",
    "| `+94-781-030-736` | `94781030736` |\n",
    "| `078 103 0736` | `94781030736` |\n",
    "| `(078) 103-0736` | `94781030736` |\n",
    "\n",
    "After extraction we look up the CRM and display the patient record + bookings\n",
    "so you can see exactly what the agent has access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  User sends a greeting with their phone number ─\n",
    "# In production this arrives via WhatsApp / web-chat; here we\n",
    "# just type it into the notebook.\n",
    "# Try changing the format - the extractor handles them all:\n",
    "#   \"+94 78 10 30 736\"  |  \"0781030736\"  |  \"+94-781-030-736\"\n",
    "\n",
    "greeting = \"Hi there! I'm Anushka, and my mobile number is +94 78 10 30 736.\"\n",
    "\n",
    "#  Intelligent phone extraction + normalisation ─\n",
    "USER_ID = extract_phone(greeting)\n",
    "logger.success(f\" Extracted phone → USER_ID = {USER_ID}\")\n",
    "\n",
    "SESSION_ID = \"demo-01\"\n",
    "logger.info(f\" Session         : {SESSION_ID}\")\n",
    "\n",
    "#  Verify the user exists in CRM & show DB records ─\n",
    "print(\"\\n\" + \"=\" * 72)\n",
    "print(\" CRM Lookup - verifying user in Supabase …\")\n",
    "print(\"=\" * 72)\n",
    "\n",
    "patient_info = show_patient_table(USER_ID)\n",
    "if patient_info:\n",
    "    show_bookings_table(USER_ID)\n",
    "else:\n",
    "    logger.warning(\"Patient not in CRM - CRM demos will return 'not found'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 1 · `direct` Route — Greeting (No Tool Needed)\n",
    "\n",
    "Simple conversational queries are answered **directly** by the LLM.\n",
    "No tool is dispatched. Memory context (if any) is still injected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the same greeting the user typed (with phone number)\n",
    "resp = agent.chat(\n",
    "    user_message=greeting,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"DIRECT route - greeting (identity extracted from this message)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happened?\n",
    "\n",
    "1. **Memory recall** — checked for recent turns + long-term facts (empty on first message)\n",
    "2. **Router** — classified as `direct` (no tool needed for a greeting)\n",
    "3. **Synthesiser** — generated a friendly response directly\n",
    "4. **Memory store** — saved this turn to short-term memory for future context\n",
    "\n",
    "---\n",
    "\n",
    "## Demo 2 · `crm` Route — Patient Lookup\n",
    "\n",
    "When the user asks about appointments, records, or doctors, the router\n",
    "dispatches to the **CRM Tool** which queries the PostgreSQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agent.chat(\n",
    "    user_message=\"Can you check my upcoming appointments?\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"CRM route - lookup_patient\")\n",
    "\n",
    "#  Behind the scenes - actual DB records \n",
    "print(\"\\n What's actually in the database for this user:\")\n",
    "show_bookings_table(USER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 3 · `crm` Route — Search Doctors\n",
    "\n",
    "The CRM tool also supports doctor search by specialty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agent.chat(\n",
    "    user_message=\"I need to see a cardiologist. Who's available?\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"CRM route - search_doctors\")\n",
    "\n",
    "#  Behind the scenes - cardiologists in the DB \n",
    "session = _crm_session()\n",
    "try:\n",
    "    docs = (\n",
    "        session.query(Doctor, Specialty)\n",
    "        .join(Specialty, Doctor.specialty_id == Specialty.specialty_id)\n",
    "        .filter(Specialty.name.ilike(\"%cardiol%\"), Doctor.active == 1)\n",
    "        .limit(10)\n",
    "        .all()\n",
    "    )\n",
    "    if docs:\n",
    "        df = pd.DataFrame([{\n",
    "            \"Doctor\": f\"Dr. {d.full_name}\",\n",
    "            \"Specialty\": s.name,\n",
    "            \"Phone\": d.phone or \"-\",\n",
    "            \"License\": d.license_no or \"-\",\n",
    "        } for d, s in docs])\n",
    "        print(\"\\n Cardiologists in the DB  (Supabase → doctors table):\")\n",
    "        display(df)\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 4 · `rag` Route — Internal Knowledge Base (Hospital Policies)\n",
    "\n",
    "When the user asks about hospital policies, procedures, or services,\n",
    "the router dispatches to the **RAG Tool** which:\n",
    "1. Checks the **CAG cache** for instant answers\n",
    "2. On cache miss → searches **Qdrant** (parent-child chunks) → generates via LLM\n",
    "3. Caches the result for next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agent.chat(\n",
    "    user_message=\"What is the hospital's hand hygiene policy?\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"RAG route - internal KB (Qdrant KB + Qdrant CAG cache)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 5 · `web_search` Route — Real-Time Information\n",
    "\n",
    "For questions needing live data (hours, directions, news), the router\n",
    "dispatches to **Tavily Web Search**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = agent.chat(\n",
    "    user_message=\"What are the current visiting hours at Nawaloka Hospital?\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"WEB SEARCH route - Tavily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 6 · Memory Continuity — Allergy Trigger + Recall\n",
    "\n",
    "This tests the full memory loop:\n",
    "1. **User mentions critical info** (\"I'm allergic to penicillin, always remember\")\n",
    "2. The **distiller** extracts it as a long-term fact\n",
    "3. A follow-up question tests whether the agent **recalls** it correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The phrase \"always remember\" triggers distillation\n",
    "resp = agent.chat(\n",
    "    user_message=\"By the way, I'm allergic to penicillin. Please always remember that.\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"Memory trigger - 'always remember'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test recall - the agent should remember everything from this session\n",
    "resp = agent.chat(\n",
    "    user_message=\"What do you know about me so far?\",\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID,\n",
    ")\n",
    "\n",
    "show_response(resp, label=\"Memory recall - full context test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 7 · Multi-Turn Conversation (All Routes)\n",
    "\n",
    "A complete conversation that exercises **all routes** in sequence,\n",
    "showing how context builds progressively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh session for a clean multi-turn demo\n",
    "MULTI_SESSION = \"demo-multiturn\"\n",
    "\n",
    "conversation = [\n",
    "    \"Hello, it's Anushka again. I need some help today.\",               # → direct\n",
    "    \"I take atenolol 50mg daily for blood pressure, please remember.\",   # → direct + distill\n",
    "    \"Can you find a cardiologist for me?\",                               # → crm (search_doctors)\n",
    "    \"What is the emergency evacuation procedure at the hospital?\",       # → rag\n",
    "    \"What medications and allergies do you have on file for me?\",        # → direct (from memory)\n",
    "]\n",
    "\n",
    "print(\" Multi-Turn Conversation Flow\")\n",
    "print(\"=\" * 72)\n",
    "\n",
    "for i, msg in enumerate(conversation, 1):\n",
    "    print(f\"\\n Turn {i}: {msg}\")\n",
    "    print(\"-\" * 72)\n",
    "    \n",
    "    resp = agent.chat(\n",
    "        user_message=msg,\n",
    "        user_id=USER_ID,\n",
    "        session_id=MULTI_SESSION,\n",
    "    )\n",
    "    \n",
    "    print(f\"  Route: {resp.route}\" + (f\" / {resp.action}\" if resp.action else \"\"))\n",
    "    print(f\"  {resp.latency_ms}ms\")\n",
    "    print(f\" {resp.answer[:250]}{'...' if len(resp.answer) > 250 else ''}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 72)\n",
    "logger.success(\" Multi-turn conversation complete!\")\n",
    "print(\" Check LangFuse dashboard for the full trace waterfall.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Demo 8 · Observability — LangFuse Traces\n",
    "\n",
    "Every `.chat()` call creates a **LangFuse trace** with nested spans:\n",
    "\n",
    "```\n",
    "agent_chat (trace)\n",
    "  ├─ memory_recall (span)\n",
    "  │    └─ memory_recall_inner (span)\n",
    "  ├─ router (generation)        ← LLM call: tokens, cost, model\n",
    "  ├─ tool_dispatch (span)\n",
    "  │    └─ crm_dispatch | rag_search | web_search (span)\n",
    "  ├─ synthesiser (generation)   ← LLM call: tokens, cost, model\n",
    "  ├─ memory_store (span)\n",
    "  └─ memory_distill (span)\n",
    "       └─ distill_facts (generation) ← if triggered\n",
    "```\n",
    "\n",
    "Open your **LangFuse dashboard** → Traces to see:\n",
    "- Per-step latency waterfall\n",
    "- Token usage and cost per LLM call\n",
    "- Input/output of every step\n",
    "- Memory context that was injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from infrastructure.observability import flush\n",
    "\n",
    "# Flush any pending LangFuse events\n",
    "flush()\n",
    "\n",
    "langfuse_host = os.getenv(\"LANGFUSE_HOST\", \"https://cloud.langfuse.com\")\n",
    "print(f\" LangFuse dashboard: {langfuse_host}\")\n",
    "print(\"   Navigate to Traces → filter by tag 'agent' to see all traces from this notebook.\")\n",
    "print(\"   Each trace shows the full pipeline: recall → route → dispatch → synthesise → store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Component | Role | Key File |\n",
    "|-----------|------|----------|\n",
    "| **Router** | LLM classifies intent → `crm \\| rag \\| web_search \\| direct` | `agents/router.py` |\n",
    "| **CRM Tool** | Patient lookup, doctor search, booking CRUD | `agents/tools/crm_tool.py` |\n",
    "| **RAG Tool** | Qdrant KB search + Qdrant CAG cache → LLM answer | `agents/tools/rag_tool.py` |\n",
    "| **Web Search** | Tavily real-time search | `agents/tools/web_search_tool.py` |\n",
    "| **Synthesiser** | Merges memory + tool output → natural response | `agents/orchestrator.py` |\n",
    "| **Memory Recall** | ST turns + LT facts with token budget | `memory/memory_ops.py` |\n",
    "| **Memory Distill** | Extracts LT facts from conversation | `memory/memory_ops.py` |\n",
    "| **LangFuse** | Traces every step (cost, latency, I/O) | `infrastructure/observability.py` |\n",
    "\n",
    "### Next Notebooks\n",
    "- **02**: Deep dive into memory capture and distillation (4 memory types)\n",
    "- **03**: Memory store and recall — how context makes the agent smarter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
